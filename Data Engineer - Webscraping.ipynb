{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Data Engineer - Webscraping"}, {"metadata": {}, "cell_type": "markdown", "source": "## Objectives\n\n\n*    webscraping\n"}, {"metadata": {}, "cell_type": "markdown", "source": "we are going to be using Python and several Python libraries. Some of these libraries might be installed in our lab environment. Others may need to be installed by us. The cells below will install these libraries when executed.\n"}, {"metadata": {}, "cell_type": "code", "source": "#!pip install pandas\n!pip install bs4\n#!pip install requests\n!pip install requests", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Collecting bs4\n  Downloading bs4-0.0.1.tar.gz (1.1 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from bs4) (4.9.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.2.1)\nBuilding wheels for collected packages: bs4\n  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=87c90a57b9c6c225cd16d17637244e7ac35598077dd79c702b453fb791b5783e\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\nSuccessfully built bs4\nInstalling collected packages: bs4\nSuccessfully installed bs4-0.0.1\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (2.25.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests) (1.26.6)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests) (2021.10.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests) (3.0.4)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Imports\n\nlets Import any additional libraries I may need here."}, {"metadata": {}, "cell_type": "code", "source": "from bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\nimport numpy as np", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Beautiful Soup Objects\n\nBeautiful Soup is a Python library for pulling data out of HTML and XML files, we will focus on HTML files. This is accomplished by representing the HTML as a set of objects with methods used to parse the HTML. We can navigate the HTML as a tree and/or filter out what we are looking for.\n\nConsider the following HTML:\n"}, {"metadata": {}, "cell_type": "code", "source": "%%html\n<!DOCTYPE html>\n<html>\n<head>\n<title>Page Title</title>\n</head>\n<body>\n<h3><b id='boldest'>Lebron James</b></h3>\n<p> Salary: $ 92,000,000 </p>\n<h3> Stephen Curry</h3>\n<p> Salary: $85,000, 000 </p>\n<h3> Kevin Durant </h3>\n<p> Salary: $73,200, 000</p>\n</body>\n</html>", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<!DOCTYPE html>\n<html>\n<head>\n<title>Page Title</title>\n</head>\n<body>\n<h3><b id='boldest'>Lebron James</b></h3>\n<p> Salary: $ 92,000,000 </p>\n<h3> Stephen Curry</h3>\n<p> Salary: $85,000, 000 </p>\n<h3> Kevin Durant </h3>\n<p> Salary: $73,200, 000</p>\n</body>\n</html>\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "We can store it as a string in the variable HTML:"}, {"metadata": {}, "cell_type": "code", "source": "html=\"<!DOCTYPE html><html><head><title>Page Title</title></head><body><h3><b id='boldest'>Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>\"", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "To parse a document, pass it into the BeautifulSoup constructor, the BeautifulSoup object, which represents the document as a nested data structure:"}, {"metadata": {}, "cell_type": "code", "source": "soup = BeautifulSoup(html, 'html5lib')", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nFirst, the document is converted to Unicode, (similar to ASCII), and HTML entities are converted to Unicode characters. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. The BeautifulSoup object can create other types of objects. In this lab, we will cover BeautifulSoup and Tag objects that for the purposes of this lab are identical, and NavigableString objects.\n\nWe can use the method prettify() to display the HTML in the nested structure:\n"}, {"metadata": {}, "cell_type": "code", "source": "print(soup.prettify())", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "<!DOCTYPE html>\n<html>\n <head>\n  <title>\n   Page Title\n  </title>\n </head>\n <body>\n  <h3>\n   <b id=\"boldest\">\n    Lebron James\n   </b>\n  </h3>\n  <p>\n   Salary: $ 92,000,000\n  </p>\n  <h3>\n   Stephen Curry\n  </h3>\n  <p>\n   Salary: $85,000, 000\n  </p>\n  <h3>\n   Kevin Durant\n  </h3>\n  <p>\n   Salary: $73,200, 000\n  </p>\n </body>\n</html>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Tags\n\nLet's say we want the title of the page and the name of the top paid player we can use the Tag. The Tag object corresponds to an HTML tag in the original document, for example, the tag title.\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\ntag_object=soup.title\nprint(\"tag object:\",tag_object)\n\n", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "tag object: <title>Page Title</title>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nwe can see the tag type bs4.element.Tag\n"}, {"metadata": {}, "cell_type": "code", "source": "print(\"tag object type:\",type(tag_object))\n", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "tag object type: <class 'bs4.element.Tag'>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "If there is more than one Tag with the same name, the first element with that Tag name is called, this corresponds to the most paid player:"}, {"metadata": {}, "cell_type": "code", "source": "tag_object=soup.h3\ntag_object", "execution_count": 24, "outputs": [{"output_type": "execute_result", "execution_count": 24, "data": {"text/plain": "<h3><b id=\"boldest\">Lebron James</b></h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Enclosed in the bold attribute b, it helps to use the tree representation. We can navigate down the tree using the child attribute to get the name."}, {"metadata": {}, "cell_type": "markdown", "source": "# Children, Parents, and Siblings\n\nAs stated above the Tag object is a tree of objects we can access the child of the tag or navigate down the branch as follows:\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\ntag_child =tag_object.b\ntag_child\n\n", "execution_count": 25, "outputs": [{"output_type": "execute_result", "execution_count": 25, "data": {"text/plain": "<b id=\"boldest\">Lebron James</b>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "we can access the parent with the  parent"}, {"metadata": {}, "cell_type": "code", "source": "parent_tag=tag_child.parent\nparent_tag", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "<h3><b id=\"boldest\">Lebron James</b></h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nthis is identical to\n"}, {"metadata": {}, "cell_type": "code", "source": "tag_object", "execution_count": 27, "outputs": [{"output_type": "execute_result", "execution_count": 27, "data": {"text/plain": "<h3><b id=\"boldest\">Lebron James</b></h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\ntag_object parent is the body element.\n"}, {"metadata": {}, "cell_type": "code", "source": "tag_object.parent", "execution_count": 28, "outputs": [{"output_type": "execute_result", "execution_count": 28, "data": {"text/plain": "<body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\ntag_object sibling is the paragraph element\n"}, {"metadata": {}, "cell_type": "code", "source": "sibling_1=tag_object.next_sibling\nsibling_1", "execution_count": 29, "outputs": [{"output_type": "execute_result", "execution_count": 29, "data": {"text/plain": "<p> Salary: $ 92,000,000 </p>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nsibling_2 is the header element which is also a sibling of both sibling_1 and tag_object\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\nsibling_2=sibling_1.next_sibling\nsibling_2\n\n", "execution_count": 30, "outputs": [{"output_type": "execute_result", "execution_count": 30, "data": {"text/plain": "<h3> Stephen Curry</h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "# next_sibling\n\nUsing the object sibling_2 and the method next_sibling to find the salary of Stephen Curry:\n"}, {"metadata": {}, "cell_type": "code", "source": "sibling_2=sibling_1.next_sibling\nsibling_2", "execution_count": 31, "outputs": [{"output_type": "execute_result", "execution_count": 31, "data": {"text/plain": "<h3> Stephen Curry</h3>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "# HTML Attributes\n\nIf the tag has attributes, the tag id=\"boldest\" has an attribute id whose value is boldest. You can access a tag\u2019s attributes by treating the tag like a dictionary:\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\ntag_child['id']\n\n", "execution_count": 32, "outputs": [{"output_type": "execute_result", "execution_count": 32, "data": {"text/plain": "'boldest'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "that dictionary directly as attrs is  accessed by:"}, {"metadata": {}, "cell_type": "code", "source": "tag_child.attrs", "execution_count": 33, "outputs": [{"output_type": "execute_result", "execution_count": 33, "data": {"text/plain": "{'id': 'boldest'}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nwe can also work with Multi-valued attribute.\n\nWe can also obtain the content if the attribute of the tag using the Python get() method.\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\ntag_child.get('id')\n\n", "execution_count": 34, "outputs": [{"output_type": "execute_result", "execution_count": 34, "data": {"text/plain": "'boldest'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\nNavigable String\n\nA string corresponds to a bit of text or content within a tag. Beautiful Soup uses the NavigableString class to contain this text. In our HTML we can obtain the name of the first player by extracting the sting of the Tag object tag_child as follows:\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\ntag_string=tag_child.string\ntag_string\n\n", "execution_count": 35, "outputs": [{"output_type": "execute_result", "execution_count": 35, "data": {"text/plain": "'Lebron James'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "we can verify the type is Navigable String"}, {"metadata": {}, "cell_type": "code", "source": "type(tag_string)", "execution_count": 36, "outputs": [{"output_type": "execute_result", "execution_count": 36, "data": {"text/plain": "bs4.element.NavigableString"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "A NavigableString is just like a Python string or Unicode string, to be more precise. The main difference is that it also supports some BeautifulSoup features. We can covert it to sting object in Python:"}, {"metadata": {}, "cell_type": "code", "source": "\n\nunicode_string = str(tag_string)\nunicode_string\n\n", "execution_count": 37, "outputs": [{"output_type": "execute_result", "execution_count": 37, "data": {"text/plain": "'Lebron James'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Filter\n\nFilters allow you to find complex patterns, the simplest filter is a string. In this section we will pass a string to a different filter method and Beautiful Soup will perform a match against that exact string. Consider the following HTML of rocket launchs:\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\n%%html\n<table>\n  <tr>\n    <td id='flight' >Flight No</td>\n    <td>Launch site</td> \n    <td>Payload mass</td>\n   </tr>\n  <tr> \n    <td>1</td>\n    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n    <td>300 kg</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n    <td>94 kg</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n    <td>80 kg</td>\n  </tr>\n</table>\n\n", "execution_count": 38, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n  <tr>\n    <td id='flight' >Flight No</td>\n    <td>Launch site</td> \n    <td>Payload mass</td>\n   </tr>\n  <tr> \n    <td>1</td>\n    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida</a></td>\n    <td>300 kg</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td>\n    <td>94 kg</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td>\n    <td>80 kg</td>\n  </tr>\n</table>\n\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "We can store it as a string in the variable table:"}, {"metadata": {}, "cell_type": "code", "source": "table=\"<table><tr><td id='flight'>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td><td>80 kg</td></tr></table>\"", "execution_count": 40, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "table_bs = BeautifulSoup(table, 'html5lib')", "execution_count": 41, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### find All\n\nThe find_all() method looks through a tag\u2019s descendants and retrieves all descendants that match your filters.\n\nThe Method signature for find_all(name, attrs, recursive, string, limit, **kwargs)\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Name\n\nWhen we set the name parameter to a tag name, the method will extract all the tags with that name and its children.\n"}, {"metadata": {}, "cell_type": "code", "source": "table_rows=table_bs.find_all('tr')\ntable_rows", "execution_count": 42, "outputs": [{"output_type": "execute_result", "execution_count": 42, "data": {"text/plain": "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "The result is a Python Iterable just like a list, each element is a tag object:"}, {"metadata": {}, "cell_type": "code", "source": "first_row =table_rows[0]\nfirst_row", "execution_count": 44, "outputs": [{"output_type": "execute_result", "execution_count": 44, "data": {"text/plain": "<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nThe type is tag\n"}, {"metadata": {}, "cell_type": "code", "source": "print(type(first_row))", "execution_count": 45, "outputs": [{"output_type": "stream", "text": "<class 'bs4.element.Tag'>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "we can obtain the child"}, {"metadata": {}, "cell_type": "code", "source": "first_row.td", "execution_count": 46, "outputs": [{"output_type": "execute_result", "execution_count": 46, "data": {"text/plain": "<td id=\"flight\">Flight No</td>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "If we iterate through the list, each element corresponds to a row in the table:"}, {"metadata": {}, "cell_type": "code", "source": "for i,row in enumerate(table_rows):\n    print(\"row\",i,\"is\",row)\n    ", "execution_count": 47, "outputs": [{"output_type": "stream", "text": "row 0 is <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>\nrow 1 is <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>\nrow 2 is <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>\nrow 3 is <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "As row is a cell object, we can apply the method find_all to it and extract table cells in the object cells using the tag td, this is all the children with the name td. The result is a list, each element corresponds to a cell and is a Tag object, we can iterate through this list as well. We can extract the content using the string attribute."}, {"metadata": {}, "cell_type": "code", "source": "for i,row in enumerate(table_rows):\n    print(\"row\",i)\n    cells=row.find_all('td')\n    for j,cell in enumerate(cells):\n        print('colunm',j,\"cell\",cell)", "execution_count": 48, "outputs": [{"output_type": "stream", "text": "row 0\ncolunm 0 cell <td id=\"flight\">Flight No</td>\ncolunm 1 cell <td>Launch site</td>\ncolunm 2 cell <td>Payload mass</td>\nrow 1\ncolunm 0 cell <td>1</td>\ncolunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>\ncolunm 2 cell <td>300 kg</td>\nrow 2\ncolunm 0 cell <td>2</td>\ncolunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\ncolunm 2 cell <td>94 kg</td>\nrow 3\ncolunm 0 cell <td>3</td>\ncolunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>\ncolunm 2 cell <td>80 kg</td>\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "If we use a list we can match against any item in that list."}, {"metadata": {}, "cell_type": "code", "source": "list_input=table_bs .find_all(name=[\"tr\", \"td\"])\nlist_input", "execution_count": 50, "outputs": [{"output_type": "execute_result", "execution_count": 50, "data": {"text/plain": "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n <td id=\"flight\">Flight No</td>,\n <td>Launch site</td>,\n <td>Payload mass</td>,\n <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n <td>1</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>,\n <td>300 kg</td>,\n <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n <td>2</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n <td>94 kg</td>,\n <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>,\n <td>3</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>,\n <td>80 kg</td>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Attributes\n\nIf the argument is not recognized it will be turned into a filter on the tag\u2019s attributes. For example the id argument, Beautiful Soup will filter against each tag\u2019s id attribute. For example, the first td elements have a value of id of flight, therefore we can filter based on that id value.\n"}, {"metadata": {}, "cell_type": "code", "source": "table_bs.find_all(id=\"flight\")", "execution_count": 51, "outputs": [{"output_type": "execute_result", "execution_count": 51, "data": {"text/plain": "[<td id=\"flight\">Flight No</td>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "We can find all the elements that have links to the Florida Wikipedia page:"}, {"metadata": {}, "cell_type": "code", "source": "list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\nlist_input", "execution_count": 52, "outputs": [{"output_type": "execute_result", "execution_count": 52, "data": {"text/plain": "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "If we set the href attribute to True, regardless of what the value is, the code finds all tags with href value:"}, {"metadata": {}, "cell_type": "code", "source": "table_bs.find_all(href=True)", "execution_count": 53, "outputs": [{"output_type": "execute_result", "execution_count": 53, "data": {"text/plain": "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n <a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a>,\n <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nThere are other methods for dealing with attributes and other related methods;"}, {"metadata": {}, "cell_type": "markdown", "source": "find_all\n\nUsing the logic above, find all the elements without href value\n"}, {"metadata": {}, "cell_type": "code", "source": "table_bs.find_all(href=False)", "execution_count": 55, "outputs": [{"output_type": "execute_result", "execution_count": 55, "data": {"text/plain": "[<html><head></head><body><table><tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody></table></body></html>,\n <head></head>,\n <body><table><tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody></table></body>,\n <table><tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody></table>,\n <tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody>,\n <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n <td id=\"flight\">Flight No</td>,\n <td>Launch site</td>,\n <td>Payload mass</td>,\n <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n <td>1</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>,\n <a></a>,\n <td>300 kg</td>,\n <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n <td>2</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n <td>94 kg</td>,\n <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>,\n <td>3</td>,\n <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>,\n <a> </a>,\n <td>80 kg</td>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Using the soup object soup, find the element with the id attribute content set to \"boldest\"."}, {"metadata": {}, "cell_type": "code", "source": "soup.find_all(id=\"boldest\") ", "execution_count": 56, "outputs": [{"output_type": "execute_result", "execution_count": 56, "data": {"text/plain": "[<b id=\"boldest\">Lebron James</b>]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\nstring\n\nWith string you can search for strings instead of tags, where we find all the elments with Florida:\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\ntable_bs.find_all(string=\"Florida\")\n\n", "execution_count": 57, "outputs": [{"output_type": "execute_result", "execution_count": 57, "data": {"text/plain": "['Florida', 'Florida']"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\nfind\n\nThe find_all() method scans the entire document looking for results, it\u2019s if you are looking for one element you can use the find() method to find the first element in the document. Consider the following two table:\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\n%%html\n<h3>Rocket Launch </h3>\n\n<p>\n<table class='rocket'>\n  <tr>\n    <td>Flight No</td>\n    <td>Launch site</td> \n    <td>Payload mass</td>\n  </tr>\n  <tr>\n    <td>1</td>\n    <td>Florida</td>\n    <td>300 kg</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td>Texas</td>\n    <td>94 kg</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td>Florida </td>\n    <td>80 kg</td>\n  </tr>\n</table>\n</p>\n<p>\n\n<h3>Pizza Party  </h3>\n  \n    \n<table class='pizza'>\n  <tr>\n    <td>Pizza Place</td>\n    <td>Orders</td> \n    <td>Slices </td>\n   </tr>\n  <tr>\n    <td>Domino's Pizza</td>\n    <td>10</td>\n    <td>100</td>\n  </tr>\n  <tr>\n    <td>Little Caesars</td>\n    <td>12</td>\n    <td >144 </td>\n  </tr>\n  <tr>\n    <td>Papa John's </td>\n    <td>15 </td>\n    <td>165</td>\n  </tr>\n\n", "execution_count": 58, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<h3>Rocket Launch </h3>\n\n<p>\n<table class='rocket'>\n  <tr>\n    <td>Flight No</td>\n    <td>Launch site</td> \n    <td>Payload mass</td>\n  </tr>\n  <tr>\n    <td>1</td>\n    <td>Florida</td>\n    <td>300 kg</td>\n  </tr>\n  <tr>\n    <td>2</td>\n    <td>Texas</td>\n    <td>94 kg</td>\n  </tr>\n  <tr>\n    <td>3</td>\n    <td>Florida </td>\n    <td>80 kg</td>\n  </tr>\n</table>\n</p>\n<p>\n\n<h3>Pizza Party  </h3>\n  \n    \n<table class='pizza'>\n  <tr>\n    <td>Pizza Place</td>\n    <td>Orders</td> \n    <td>Slices </td>\n   </tr>\n  <tr>\n    <td>Domino's Pizza</td>\n    <td>10</td>\n    <td>100</td>\n  </tr>\n  <tr>\n    <td>Little Caesars</td>\n    <td>12</td>\n    <td >144 </td>\n  </tr>\n  <tr>\n    <td>Papa John's </td>\n    <td>15 </td>\n    <td>165</td>\n  </tr>\n\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "We store the HTML as a Python string and assign two_tables:\n"}, {"metadata": {}, "cell_type": "code", "source": "two_tables=\"<h3>Rocket Launch </h3><p><table class='rocket'><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class='pizza'><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td >144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr>\"", "execution_count": 59, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We create a BeautifulSoup object two_tables_bs"}, {"metadata": {}, "cell_type": "code", "source": "two_tables_bs= BeautifulSoup(two_tables, 'html.parser')", "execution_count": 60, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nWe can find the first table using the tag name table\n"}, {"metadata": {}, "cell_type": "code", "source": "two_tables_bs.find(\"table\")", "execution_count": 61, "outputs": [{"output_type": "execute_result", "execution_count": 61, "data": {"text/plain": "<table class=\"rocket\"><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nWe can filter on the class attribute to find the second table, but because class is a keyword in Python, we add an underscore.\n"}, {"metadata": {}, "cell_type": "code", "source": "two_tables_bs.find(\"table\",class_='pizza')", "execution_count": 63, "outputs": [{"output_type": "execute_result", "execution_count": 63, "data": {"text/plain": "<table class=\"pizza\"><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td>144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr></table>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\nDownloading And Scraping The Contents Of A Web Page\n\nWe Download the contents of the web page:\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\nurl = \"http://www.ibm.com\"\n\n", "execution_count": 64, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We use get to download the contents of the webpage in text format and store in a variable called data:"}, {"metadata": {}, "cell_type": "code", "source": "\n\ndata  = requests.get(url).text \n\n", "execution_count": 65, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nWe create a BeautifulSoup object using the BeautifulSoup constructor\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\nsoup = BeautifulSoup(data,\"html5lib\")  ", "execution_count": 66, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nScrape all links\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\nfor link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag <a>\n\n    print(link.get('href'))\n\n", "execution_count": 67, "outputs": [{"output_type": "stream", "text": "#main-content\nhttp://www.ibm.com\nhttps://www.ibm.com/cloud/satellite?lnk=ushpv18l1\nhttps://www.ibm.com/security/executive-order-cybersecurity?lnk=ushpv18f1\nhttps://www.ibm.com/consulting/operations/?lnk=ushpv18f2\nhttps://www.ibm.com/thought-leadership/institute-business-value/c-suite-study/cio?lnk=ushpv18f3\nhttps://developer.ibm.com/callforcode/awards/?lnk=ushpv18f4\nhttps://www.ibm.com/products/offers-and-discounts?link=ushpv18t5&lnk2=trial_mktpl_MPDISC\nhttps://www.ibm.com/products/hosted-security-intelligence?lnk=ushpv18t1&lnk2=trial_QRadarCloud&psrc=none&pexp=def\nhttps://www.ibm.com/products/mq?lnk=ushpv18t2&lnk2=trial_MQ&psrc=none&pexp=def\nhttps://www.ibm.com/products/watson-assistant?lnk=ushpv18t3&lnk2=trial_WatAssist&psrc=none&pexp=def\nhttps://www.ibm.com/products/cognos-analytics?lnk=ushpv18t4&lnk2=trial_CogAnalytics&psrc=none&pexp=def\nhttps://www.ibm.com/search?lnk=ushpv18srch&locale=en-us&q=\nhttps://www.ibm.com/products?lnk=ushpv18p1&lnk2=trial_mktpl&psrc=none&pexp=def\nhttps://www.ibm.com/cloud/hybrid?lnk=ushpv18pt14\nhttps://www.ibm.com/watson?lnk=ushpv18pt17\nhttps://www.ibm.com/it-infrastructure?lnk=ushpv18pt19\nhttps://www.ibm.com/us-en/products/categories?technologyTopics%5B0%5D%5B0%5D=cat.topic:Blockchain&isIBMOffering%5B0%5D=true&lnk=ushpv18pt4\nhttps://www.ibm.com/us-en/products/category/technology/security?lnk=ushpv18pt9\nhttps://www.ibm.com/us-en/products/category/technology/analytics?lnk=ushpv18pt1\nhttps://www.ibm.com/cloud/automation?lnk=ushpv18ct21\nhttps://www.ibm.com/quantum-computing?lnk=ushpv18pt16\nhttps://www.ibm.com/mysupport/s/?language=en_US&lnk=ushpv18ct11\nhttps://www.ibm.com/training/?lnk=ushpv18ct15\nhttps://developer.ibm.com/?lnk=ushpv18ct9\nhttps://www.ibm.com/garage?lnk=ushpv18pt18\nhttps://www.ibm.com/docs/en?lnk=ushpv18ct14\nhttps://www.redbooks.ibm.com/?lnk=ushpv18ct10\nhttps://www-03.ibm.com/employment/technicaltalent/developer/?lnk=ushpv18ct2\nhttps://www.ibm.com/security/zero-trust?lnk=ushpv18vn1\nhttps://www.ibm.com/security/zero-trust?lnk=ushpv18vn1\nhttps://www.ibm.com/\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "\nScrape all images Tags"}, {"metadata": {}, "cell_type": "code", "source": "\n\nfor link in soup.find_all('img'):# in html image is represented by the tag <img>\n    print(link)\n    print(link.get('src'))\n\n", "execution_count": 68, "outputs": [{"output_type": "stream", "text": "<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTA1NSIgaGVpZ2h0PSI1MjcuNSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTA1NSIgaGVpZ2h0PSI1MjcuNSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"leadspace mobile image\" class=\"ibm-resize\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/c6/13/20210628-Cloud-Satellite-mobile-25980-720x360.jpg\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/c6/13/20210628-Cloud-Satellite-mobile-25980-720x360.jpg\n<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjMyMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjMyMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"U.S. Executive Order 14028\n\" class=\"ibm-resize ibm-ab-image featured-image\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/80/38/20211107-26227%20X-Force-executive-order-444x320.jpg\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/80/38/20211107-26227%20X-Force-executive-order-444x320.jpg\n<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjMyMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjMyMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"IBM Consulting for operations\" class=\"ibm-resize ibm-ab-image featured-image\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/89/4a/20211115-f-ibm-consulting-operations-26241.jpg \" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/89/4a/20211115-f-ibm-consulting-operations-26241.jpg \n<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjMyMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjMyMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"2021 study: The CIO Revolution\" class=\"ibm-resize ibm-ab-image featured-image\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/15/30/20211115-f-ibv-cio-revolution-26181.png\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/15/30/20211115-f-ibv-cio-revolution-26181.png\n<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjMyMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjMyMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"Call for Code 2021: the finalists\" class=\"ibm-resize ibm-ab-image featured-image\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/e2/0b/20211115-26256-call-for-code-winners-444x320.jpg\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/e2/0b/20211115-26256-call-for-code-winners-444x320.jpg\n<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjI2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjI2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"IBM Security QRadar on Cloud\" class=\"ibm-resize ibm-ab-image trials-image\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/bb/88/QRadar-on-Cloud-21400-700x420.png\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/bb/88/QRadar-on-Cloud-21400-700x420.png\n<img alt=\"IBM Security QRadar on Cloud\" class=\"ibm-resize ibm-ab-image trials-image\" decoding=\"async\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\ndata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjI2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjI2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"IBM MQ\" class=\"ibm-resize ibm-ab-image trials-image\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/dc/94/MQ-on-Cloud-19011-700x420.png\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/dc/94/MQ-on-Cloud-19011-700x420.png\n<img alt=\"IBM MQ\" class=\"ibm-resize ibm-ab-image trials-image\" decoding=\"async\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\ndata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjI2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjI2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"IBM Watson Assistant\" class=\"ibm-resize ibm-ab-image trials-image\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/df/39/Watson-Assistant-23212-700x420.png\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/df/39/Watson-Assistant-23212-700x420.png\n<img alt=\"IBM Watson Assistant\" class=\"ibm-resize ibm-ab-image trials-image\" decoding=\"async\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\ndata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n<img alt=\"\" aria-hidden=\"true\" role=\"presentation\" src=\"data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjI2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\" style=\"max-width:100%;display:block;margin:0;border:none;padding:0\"/>\ndata:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDQwIiBoZWlnaHQ9IjI2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2ZXJzaW9uPSIxLjEiLz4=\n<img alt=\"IBM Cognos Analytics with Watson\" class=\"ibm-resize ibm-ab-image trials-image\" decoding=\"async\" src=\"https://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/6a/a5/Cognos-Analytics-20626-700x420.png\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\nhttps://1.dam.s81c.com/public/content/dam/worldwide-content/homepage/ul/g/6a/a5/Cognos-Analytics-20626-700x420.png\n<img alt=\"IBM Cognos Analytics with Watson\" class=\"ibm-resize ibm-ab-image trials-image\" decoding=\"async\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%\"/>\ndata:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "\nScrape data from HTML tables"}, {"metadata": {}, "cell_type": "code", "source": "#The below url contains an html table with data about colors and color codes.\nurl = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\"", "execution_count": 69, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Before proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check how many rows and columns are there in the color table."}, {"metadata": {}, "cell_type": "code", "source": "# get the contents of the webpage in text format and store in a variable called data\ndata  = requests.get(url).text", "execution_count": 70, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n\nsoup = BeautifulSoup(data,\"html5lib\")\n\n", "execution_count": 71, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#find a html table in the web page\ntable = soup.find('table') # in html table is represented by the tag <table>", "execution_count": 72, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n\n#Get all rows from the table\nfor row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n    # Get all columns in each row.\n    cols = row.find_all('td') # in html a column is represented by the tag <td>\n    color_name = cols[2].string # store the value in column 3 as color_name\n    color_code = cols[3].string # store the value in column 4 as color_code\n    print(\"{}--->{}\".format(color_name,color_code))\n\n", "execution_count": 73, "outputs": [{"output_type": "stream", "text": "Color Name--->None\nlightsalmon--->#FFA07A\nsalmon--->#FA8072\ndarksalmon--->#E9967A\nlightcoral--->#F08080\ncoral--->#FF7F50\ntomato--->#FF6347\norangered--->#FF4500\ngold--->#FFD700\norange--->#FFA500\ndarkorange--->#FF8C00\nlightyellow--->#FFFFE0\nlemonchiffon--->#FFFACD\npapayawhip--->#FFEFD5\nmoccasin--->#FFE4B5\npeachpuff--->#FFDAB9\npalegoldenrod--->#EEE8AA\nkhaki--->#F0E68C\ndarkkhaki--->#BDB76B\nyellow--->#FFFF00\nlawngreen--->#7CFC00\nchartreuse--->#7FFF00\nlimegreen--->#32CD32\nlime--->#00FF00\nforestgreen--->#228B22\ngreen--->#008000\npowderblue--->#B0E0E6\nlightblue--->#ADD8E6\nlightskyblue--->#87CEFA\nskyblue--->#87CEEB\ndeepskyblue--->#00BFFF\nlightsteelblue--->#B0C4DE\ndodgerblue--->#1E90FF\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Scrape data from HTML tables into a DataFrame using BeautifulSoup and Pandas"}, {"metadata": {}, "cell_type": "code", "source": "\n\nimport pandas as pd\n\n", "execution_count": 74, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#The below url contains html tables with data about world population.\nurl = \"https://en.wikipedia.org/wiki/World_population\"", "execution_count": 75, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nBefore proceeding to scrape a web site, you need to examine the contents, and the way data is organized on the website. Open the above url in your browser and check the tables on the webpage.\n"}, {"metadata": {}, "cell_type": "code", "source": "# get the contents of the webpage in text format and store in a variable called data\ndata  = requests.get(url).text\n\n", "execution_count": 77, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "soup = BeautifulSoup(data,\"html5lib\")", "execution_count": 78, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#find all html tables in the web page\ntables = soup.find_all('table') # in html table is represented by the tag <table>", "execution_count": 79, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n\n# we can see how many tables were found by checking the length of the tables list\nlen(tables)\n\n", "execution_count": 80, "outputs": [{"output_type": "execute_result", "execution_count": 80, "data": {"text/plain": "26"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nAssume that we are looking for the 10 most densly populated countries table, we can look through the tables list and find the right one we are look for based on the data in each table or we can search for the table name if it is in the table but this option might not always work.\n"}, {"metadata": {}, "cell_type": "code", "source": "for index,table in enumerate(tables):\n    if (\"10 most densely populated countries\" in str(table)):\n        table_index = index\nprint(table_index)", "execution_count": 81, "outputs": [{"output_type": "stream", "text": "5\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "See if you can locate the table name of the table, 10 most densly populated countries, below."}, {"metadata": {}, "cell_type": "code", "source": "print(tables[table_index].prettify())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n\npopulation_data = pd.DataFrame(columns=[\"Rank\", \"Country\", \"Population\", \"Area\", \"Density\"])\n\nfor row in tables[table_index].tbody.find_all(\"tr\"):\n    col = row.find_all(\"td\")\n    if (col != []):\n        rank = col[0].text\n        country = col[1].text\n        population = col[2].text.strip()\n        area = col[3].text.strip()\n        density = col[4].text.strip()\n        population_data = population_data.append({\"Rank\":rank, \"Country\":country, \"Population\":population, \"Area\":area, \"Density\":density}, ignore_index=True)\n\npopulation_data\n\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\nScrape data from HTML tables into a DataFrame using BeautifulSoup and read_html\n\nUsing the same url, data, soup, and tables object as in the last section we can use the read_html function to create a DataFrame.\n\nRemember the table we need is located in tables[table_index]\n\nWe can now use the pandas function read_html and give it the string version of the table as well as the flavor which is the parsing engine bs4.\n"}, {"metadata": {}, "cell_type": "code", "source": "\n\npd.read_html(str(tables[5]), flavor='bs4')\n\n", "execution_count": 82, "outputs": [{"output_type": "execute_result", "execution_count": 82, "data": {"text/plain": "[   Rank      Country  Population  Area(km2)  Density(pop/km2)\n 0     1    Singapore     5704000        710              8033\n 1     2   Bangladesh   171710000     143998              1192\n 2     3    Palestine     5266785       6020               847\n 3     4      Lebanon     6856000      10452               656\n 4     5       Taiwan    23604000      36193               652\n 5     6  South Korea    51781000      99538               520\n 6     7       Rwanda    12374000      26338               470\n 7     8        Haiti    11578000      27065               428\n 8     9  Netherlands    17660000      41526               425\n 9    10       Israel     9430000      22072               427]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "The function read_html always returns a list of DataFrames so we must pick the one we want out of the list."}, {"metadata": {}, "cell_type": "code", "source": "population_data_read_html = pd.read_html(str(tables[5]), flavor='bs4')[0]\n\npopulation_data_read_html", "execution_count": 83, "outputs": [{"output_type": "execute_result", "execution_count": 83, "data": {"text/plain": "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n0     1    Singapore     5704000        710              8033\n1     2   Bangladesh   171710000     143998              1192\n2     3    Palestine     5266785       6020               847\n3     4      Lebanon     6856000      10452               656\n4     5       Taiwan    23604000      36193               652\n5     6  South Korea    51781000      99538               520\n6     7       Rwanda    12374000      26338               470\n7     8        Haiti    11578000      27065               428\n8     9  Netherlands    17660000      41526               425\n9    10       Israel     9430000      22072               427", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Country</th>\n      <th>Population</th>\n      <th>Area(km2)</th>\n      <th>Density(pop/km2)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Singapore</td>\n      <td>5704000</td>\n      <td>710</td>\n      <td>8033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bangladesh</td>\n      <td>171710000</td>\n      <td>143998</td>\n      <td>1192</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Palestine</td>\n      <td>5266785</td>\n      <td>6020</td>\n      <td>847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Lebanon</td>\n      <td>6856000</td>\n      <td>10452</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Taiwan</td>\n      <td>23604000</td>\n      <td>36193</td>\n      <td>652</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>South Korea</td>\n      <td>51781000</td>\n      <td>99538</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Rwanda</td>\n      <td>12374000</td>\n      <td>26338</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Haiti</td>\n      <td>11578000</td>\n      <td>27065</td>\n      <td>428</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Netherlands</td>\n      <td>17660000</td>\n      <td>41526</td>\n      <td>425</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Israel</td>\n      <td>9430000</td>\n      <td>22072</td>\n      <td>427</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\nScrape data from HTML tables into a DataFrame using read_html\n\nWe can also use the read_html function to directly get DataFrames from a url.\n"}, {"metadata": {}, "cell_type": "code", "source": "dataframe_list = pd.read_html(url, flavor='bs4')", "execution_count": 84, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We can see there are 25 DataFrames just like when we used find_all on the soup object."}, {"metadata": {}, "cell_type": "code", "source": "len(dataframe_list)", "execution_count": 85, "outputs": [{"output_type": "execute_result", "execution_count": 85, "data": {"text/plain": "26"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Finally we can pick the DataFrame we need out of the list."}, {"metadata": {}, "cell_type": "code", "source": "\n\ndataframe_list[5]\n\n", "execution_count": 86, "outputs": [{"output_type": "execute_result", "execution_count": 86, "data": {"text/plain": "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n0     1    Singapore     5704000        710              8033\n1     2   Bangladesh   171710000     143998              1192\n2     3    Palestine     5266785       6020               847\n3     4      Lebanon     6856000      10452               656\n4     5       Taiwan    23604000      36193               652\n5     6  South Korea    51781000      99538               520\n6     7       Rwanda    12374000      26338               470\n7     8        Haiti    11578000      27065               428\n8     9  Netherlands    17660000      41526               425\n9    10       Israel     9430000      22072               427", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Country</th>\n      <th>Population</th>\n      <th>Area(km2)</th>\n      <th>Density(pop/km2)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Singapore</td>\n      <td>5704000</td>\n      <td>710</td>\n      <td>8033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bangladesh</td>\n      <td>171710000</td>\n      <td>143998</td>\n      <td>1192</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Palestine</td>\n      <td>5266785</td>\n      <td>6020</td>\n      <td>847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Lebanon</td>\n      <td>6856000</td>\n      <td>10452</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Taiwan</td>\n      <td>23604000</td>\n      <td>36193</td>\n      <td>652</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>South Korea</td>\n      <td>51781000</td>\n      <td>99538</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Rwanda</td>\n      <td>12374000</td>\n      <td>26338</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Haiti</td>\n      <td>11578000</td>\n      <td>27065</td>\n      <td>428</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Netherlands</td>\n      <td>17660000</td>\n      <td>41526</td>\n      <td>425</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Israel</td>\n      <td>9430000</td>\n      <td>22072</td>\n      <td>427</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "We can also use the match parameter to select the specific table we want. If the table contains a string matching the text it will be read."}, {"metadata": {}, "cell_type": "code", "source": "pd.read_html(url, match=\"10 most densely populated countries\", flavor='bs4')[0]", "execution_count": 87, "outputs": [{"output_type": "execute_result", "execution_count": 87, "data": {"text/plain": "   Rank      Country  Population  Area(km2)  Density(pop/km2)\n0     1    Singapore     5704000        710              8033\n1     2   Bangladesh   171710000     143998              1192\n2     3    Palestine     5266785       6020               847\n3     4      Lebanon     6856000      10452               656\n4     5       Taiwan    23604000      36193               652\n5     6  South Korea    51781000      99538               520\n6     7       Rwanda    12374000      26338               470\n7     8        Haiti    11578000      27065               428\n8     9  Netherlands    17660000      41526               425\n9    10       Israel     9430000      22072               427", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Country</th>\n      <th>Population</th>\n      <th>Area(km2)</th>\n      <th>Density(pop/km2)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Singapore</td>\n      <td>5704000</td>\n      <td>710</td>\n      <td>8033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Bangladesh</td>\n      <td>171710000</td>\n      <td>143998</td>\n      <td>1192</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Palestine</td>\n      <td>5266785</td>\n      <td>6020</td>\n      <td>847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Lebanon</td>\n      <td>6856000</td>\n      <td>10452</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Taiwan</td>\n      <td>23604000</td>\n      <td>36193</td>\n      <td>652</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>South Korea</td>\n      <td>51781000</td>\n      <td>99538</td>\n      <td>520</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Rwanda</td>\n      <td>12374000</td>\n      <td>26338</td>\n      <td>470</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Haiti</td>\n      <td>11578000</td>\n      <td>27065</td>\n      <td>428</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Netherlands</td>\n      <td>17660000</td>\n      <td>41526</td>\n      <td>425</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Israel</td>\n      <td>9430000</td>\n      <td>22072</td>\n      <td>427</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}